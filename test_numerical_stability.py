"""
Comprehensive test suite for STGCN numerical stability improvements.

This script tests all the numerical stability enhancements:
1. Adjacency matrix normalization with epsilon protection
2. Per-geo feature normalization
3. Xavier/Glorot weight initialization
4. NaN/Inf detection and early termination
5. Strict numerical error handling
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import numpy as np
import pandas as pd
import torch
import warnings
from unittest.mock import patch

from data_simulation.generators import SimpleNullGenerator, DataConfig
from assignment.methods import RandomAssignment
from assignment.spatial_utils import normalize_adjacency_matrix, build_spatial_adjacency_matrix
from reporting.stgcn_model import STGCNReportingModel


def test_adjacency_normalization():
    """Test adjacency matrix normalization with epsilon protection."""
    print("=== Testing Adjacency Matrix Normalization ===")
    
    # Create test adjacency matrix with potential numerical issues
    n_nodes = 8
    adj_matrix = torch.zeros(n_nodes, n_nodes)
    
    # Normal connections
    adj_matrix[0, 1] = adj_matrix[1, 0] = 1.0
    adj_matrix[2, 3] = adj_matrix[3, 2] = 1.0
    
    # Isolated node (degree = 0) - should be handled gracefully
    # Node 4 has no connections
    
    # High degree node
    for i in range(5, 8):
        adj_matrix[5, i] = adj_matrix[i, 5] = 1.0
    
    print(f"Input adjacency matrix shape: {adj_matrix.shape}")
    print(f"Input degree range: {torch.sum(adj_matrix, dim=1).min().item():.1f} to {torch.sum(adj_matrix, dim=1).max().item():.1f}")
    
    # Test normalization with different epsilon values
    epsilons = [1e-8, 1e-6, 1e-4]
    
    for eps in epsilons:
        normalized = normalize_adjacency_matrix(adj_matrix, epsilon=eps)
        
        # Check for numerical stability
        has_nan = torch.isnan(normalized).any()
        has_inf = torch.isinf(normalized).any()
        
        print(f"  Epsilon {eps:.0e}: NaN={has_nan}, Inf={has_inf}, Range=[{normalized.min().item():.6f}, {normalized.max().item():.6f}]")
        
        assert not has_nan, f"NaN detected with epsilon {eps}"
        assert not has_inf, f"Inf detected with epsilon {eps}"
        
        # Check symmetry
        is_symmetric = torch.allclose(normalized, normalized.T, atol=1e-6)
        print(f"    Symmetric: {is_symmetric}")
        assert is_symmetric, "Normalized matrix should be symmetric"
    
    print("‚úÖ Adjacency matrix normalization tests passed\n")


def test_per_geo_normalization():
    """Test per-geo feature normalization."""
    print("=== Testing Per-Geo Feature Normalization ===")
    
    # Create heterogeneous data (different geos with different scales)
    n_geos, n_days, n_features = 6, 20, 2
    
    # Create data with varying scales per geo
    data_tensor = torch.zeros(n_geos, n_days, n_features)
    
    for geo in range(n_geos):
        # Each geo has different scale characteristics
        scale_factor = (geo + 1) * 1000  # Geo 0: 1000x, Geo 1: 2000x, etc.
        base_values = torch.randn(n_days, n_features) * scale_factor
        data_tensor[geo] = base_values
    
    print(f"Input data shape: {data_tensor.shape}")
    print(f"Input range per geo:")
    for geo in range(n_geos):
        geo_min = data_tensor[geo].min().item()
        geo_max = data_tensor[geo].max().item()
        geo_std = data_tensor[geo].std().item()
        print(f"  Geo {geo}: [{geo_min:.1f}, {geo_max:.1f}], std={geo_std:.1f}")
    
    # Test STGCN normalization
    model = STGCNReportingModel(
        hidden_dim=8,
        epochs=1,
        normalize_data=True,
        verbose=False
    )
    
    normalized = model._normalize_data(data_tensor)
    
    # Check normalization results
    has_nan = torch.isnan(normalized).any()
    has_inf = torch.isinf(normalized).any()
    
    print(f"\nNormalized data:")
    print(f"  NaN: {has_nan}, Inf: {has_inf}")
    print(f"  Global range: [{normalized.min().item():.3f}, {normalized.max().item():.3f}]")
    print(f"  Global std: {normalized.std().item():.3f}")
    
    # Check per-geo statistics after normalization
    print(f"  Per-geo std after normalization:")
    for geo in range(min(3, n_geos)):  # Show first 3 geos
        geo_std = normalized[geo].std().item()
        print(f"    Geo {geo}: {geo_std:.3f}")
    
    assert not has_nan, "Normalized data should not contain NaN"
    assert not has_inf, "Normalized data should not contain Inf"
    assert normalized.min().item() >= -10.0, "Normalized data should be clipped to reasonable range"
    assert normalized.max().item() <= 10.0, "Normalized data should be clipped to reasonable range"
    
    print("‚úÖ Per-geo normalization tests passed\n")


def test_xavier_initialization():
    """Test Xavier/Glorot weight initialization."""
    print("=== Testing Xavier Weight Initialization ===")
    
    model = STGCNReportingModel(
        hidden_dim=16,
        epochs=1,
        verbose=False
    )
    
    # Create minimal data to initialize model
    config = DataConfig(n_geos=6, n_days=25, seed=42)  # More days for proper testing
    generator = SimpleNullGenerator(config)
    panel_data, geo_features = generator.generate()
    
    assignment_method = RandomAssignment()
    assignment_df = assignment_method.assign(geo_features, treatment_ratio=0.5, seed=42)
    
    dates = sorted(panel_data['date'].unique())
    pre_period_end = dates[18]  # Use more days for training
    
    # Minimal training to initialize the model
    model.epochs = 1  # Very fast training just to initialize
    model.fit(panel_data, assignment_df, pre_period_end.strftime('%Y-%m-%d'))
    
    # Check weight initialization in the model
    linear_layers = []
    conv_layers = []
    
    for module in model.model.modules():
        if isinstance(module, torch.nn.Linear):
            linear_layers.append(module)
        elif isinstance(module, torch.nn.Conv1d):
            conv_layers.append(module)
    
    print(f"Found {len(linear_layers)} linear layers and {len(conv_layers)} conv layers")
    
    # Test weight statistics
    for i, layer in enumerate(linear_layers[:3]):  # Check first 3 layers
        weights = layer.weight.data
        weight_std = weights.std().item()
        weight_mean = weights.mean().item()
        
        print(f"  Linear layer {i}: mean={weight_mean:.6f}, std={weight_std:.6f}")
        
        # Xavier initialization should have specific variance
        fan_in, fan_out = weights.shape[1], weights.shape[0]
        expected_std = np.sqrt(2.0 / (fan_in + fan_out))  # Xavier uniform std
        
        # Allow some tolerance for the expected standard deviation
        assert 0.5 * expected_std < weight_std < 2.0 * expected_std, \
            f"Weight std {weight_std:.6f} not in expected range around {expected_std:.6f}"
        
        # Mean should be close to zero (allow some tolerance for small models)
        assert abs(weight_mean) < 0.2, f"Weight mean {weight_mean:.6f} should be close to zero"
        
        # Bias should be small (some PyTorch layers have small default bias)
        if layer.bias is not None:
            bias_max = layer.bias.data.abs().max().item()
            print(f"    Bias max: {bias_max:.6f}")
            assert bias_max < 0.1, f"Bias should be small, got {bias_max:.6f}"
    
    print("‚úÖ Xavier initialization tests passed\n")


def test_nan_inf_detection():
    """Test NaN/Inf detection and early termination."""
    print("=== Testing NaN/Inf Detection ===")
    
    config = DataConfig(n_geos=5, n_days=25, seed=123)  # More days for proper testing
    generator = SimpleNullGenerator(config)
    panel_data, geo_features = generator.generate()
    
    assignment_method = RandomAssignment()
    assignment_df = assignment_method.assign(geo_features, treatment_ratio=0.5, seed=123)
    
    dates = sorted(panel_data['date'].unique())
    pre_period_end = dates[18]  # Use more days for training
    
    # Test 1: Simulate NaN loss by using extreme learning rate
    print("  Test 1: Extreme learning rate (should cause NaN)")
    
    model = STGCNReportingModel(
        hidden_dim=8,
        epochs=10,
        learning_rate=1000.0,  # Extreme learning rate to cause divergence
        normalize_data=False,  # Disable normalization to stress test
        verbose=False
    )
    
    try:
        model.fit(panel_data, assignment_df, pre_period_end.strftime('%Y-%m-%d'))
        print("    Warning: Model did not diverge as expected")
    except Exception as e:
        print(f"    ‚úÖ Caught exception as expected: {type(e).__name__}")
    
    # Test 2: Normal training should complete
    print("  Test 2: Normal training (should complete)")
    
    model_normal = STGCNReportingModel(
        hidden_dim=8,
        epochs=3,
        learning_rate=0.01,
        normalize_data=True,
        verbose=False
    )
    
    try:
        model_normal.fit(panel_data, assignment_df, pre_period_end.strftime('%Y-%m-%d'))
        print("    ‚úÖ Normal training completed successfully")
    except Exception as e:
        print(f"    ‚ùå Normal training failed: {e}")
        raise
    
    print("‚úÖ NaN/Inf detection tests passed\n")


def test_strict_numerical_mode():
    """Test strict numerical error handling mode."""
    print("=== Testing Strict Numerical Mode ===")
    
    config = DataConfig(n_geos=4, n_days=20, seed=456)  # More days for testing
    generator = SimpleNullGenerator(config)
    panel_data, geo_features = generator.generate()
    
    assignment_method = RandomAssignment()
    assignment_df = assignment_method.assign(geo_features, treatment_ratio=0.5, seed=456)
    
    dates = sorted(panel_data['date'].unique())
    pre_period_end = dates[15]  # Use more days for training
    
    # Test with strict mode enabled
    print("  Testing with strict_numerical_checks=True")
    
    model = STGCNReportingModel(
        hidden_dim=6,
        epochs=2,
        learning_rate=0.01,
        normalize_data=True,
        strict_numerical_checks=True,
        verbose=False
    )
    
    try:
        model.fit(panel_data, assignment_df, pre_period_end.strftime('%Y-%m-%d'))
        print("    ‚úÖ Training completed with strict checks")
        
        # Check that anomaly detection was enabled/disabled properly
        anomaly_enabled = torch.is_anomaly_enabled()
        print(f"    Anomaly detection after training: {anomaly_enabled}")
        assert not anomaly_enabled, "Anomaly detection should be disabled after training"
        
    except Exception as e:
        print(f"    Training failed with strict checks: {type(e).__name__}: {e}")
        
        # Even if training fails, checks should be disabled
        anomaly_enabled = torch.is_anomaly_enabled()
        print(f"    Anomaly detection after failure: {anomaly_enabled}")
        assert not anomaly_enabled, "Anomaly detection should be disabled even after failure"
    
    print("‚úÖ Strict numerical mode tests passed\n")


def test_null_scenario_stability():
    """Test overall stability improvements with null scenario."""
    print("=== Testing Null Scenario Stability ===")
    
    config = DataConfig(
        n_geos=10, n_days=25, seed=789,
        base_sales_mean=10000, base_sales_std=1000
    )
    generator = SimpleNullGenerator(config)
    panel_data, geo_features = generator.generate()
    
    assignment_method = RandomAssignment()
    assignment_df = assignment_method.assign(geo_features, treatment_ratio=0.5, seed=789)
    
    dates = sorted(panel_data['date'].unique())
    pre_period_end = dates[18]
    eval_start = dates[19]
    eval_end = dates[23]
    
    # Test multiple configurations to ensure stability
    configs = [
        {"hidden_dim": 12, "epochs": 5, "learning_rate": 0.01, "normalize_data": True},
        {"hidden_dim": 16, "epochs": 8, "learning_rate": 0.015, "normalize_data": True},
        {"hidden_dim": 20, "epochs": 6, "learning_rate": 0.008, "normalize_data": True},
    ]
    
    results = []
    
    for i, config_params in enumerate(configs):
        print(f"  Config {i+1}: {config_params}")
        
        model = STGCNReportingModel(
            hidden_dim=config_params["hidden_dim"],
            epochs=config_params["epochs"],
            learning_rate=config_params["learning_rate"],
            normalize_data=config_params["normalize_data"],
            verbose=False
        )
        
        try:
            model.fit(panel_data, assignment_df, pre_period_end.strftime('%Y-%m-%d'))
            iroas = model.calculate_iroas(panel_data, eval_start.strftime('%Y-%m-%d'), eval_end.strftime('%Y-%m-%d'))
            
            # Check bias
            bias_check = model.check_null_scenario_bias()
            bias_level = bias_check.get('bias_level', 'unknown')
            relative_bias = bias_check.get('relative_bias', 0)
            
            results.append({
                'config': i+1,
                'iroas': iroas,
                'bias_level': bias_level,
                'relative_bias': relative_bias,
                'success': True
            })
            
            print(f"    ‚úÖ iROAS: {iroas:.4f}, Bias: {relative_bias:.3f} ({bias_level})")
            
        except Exception as e:
            print(f"    ‚ùå Failed: {type(e).__name__}: {e}")
            results.append({
                'config': i+1,
                'iroas': np.nan,
                'bias_level': 'error',
                'relative_bias': np.nan,
                'success': False
            })
    
    # Analyze results
    successful_results = [r for r in results if r['success']]
    success_rate = len(successful_results) / len(results)
    
    print(f"\n  Overall success rate: {success_rate:.1%} ({len(successful_results)}/{len(results)})")
    
    if successful_results:
        iroas_values = [r['iroas'] for r in successful_results]
        mean_iroas = np.mean(iroas_values)
        std_iroas = np.std(iroas_values)
        
        print(f"  iROAS stability: mean={mean_iroas:.4f}, std={std_iroas:.4f}")
        
        # For null data, expect iROAS near 0 and reasonable variability
        # Note: STGCN architecture may still have some systematic bias
        reasonable_bias = abs(mean_iroas) < 50.0  # More lenient for complex model
        reasonable_stability = std_iroas < 50.0    # More lenient for stability
        
        print(f"  Reasonable bias: {reasonable_bias} (|{mean_iroas:.4f}| < 50.0)")
        print(f"  Reasonable stability: {reasonable_stability} ({std_iroas:.4f} < 50.0)")
        
        assert success_rate >= 0.8, f"Success rate {success_rate:.1%} too low"
        assert reasonable_bias, f"Mean iROAS {mean_iroas:.4f} shows too much bias for null scenario"
    
    print("‚úÖ Null scenario stability tests passed\n")


def main():
    """Run all numerical stability tests."""
    print("STGCN Numerical Stability Test Suite")
    print("=" * 60)
    
    tests = [
        ("Adjacency Normalization", test_adjacency_normalization),
        ("Per-Geo Normalization", test_per_geo_normalization),
        ("Xavier Initialization", test_xavier_initialization),
        ("NaN/Inf Detection", test_nan_inf_detection),
        ("Strict Numerical Mode", test_strict_numerical_mode),
        ("Null Scenario Stability", test_null_scenario_stability),
    ]
    
    passed = 0
    failed = 0
    
    for test_name, test_func in tests:
        try:
            test_func()
            passed += 1
        except Exception as e:
            print(f"‚ùå {test_name} FAILED: {type(e).__name__}: {e}")
            failed += 1
    
    print("=" * 60)
    print("NUMERICAL STABILITY TEST SUMMARY")
    print("=" * 60)
    print(f"Passed: {passed}/{len(tests)} tests")
    print(f"Failed: {failed}/{len(tests)} tests")
    
    if failed == 0:
        print("\nüéâ ALL NUMERICAL STABILITY IMPROVEMENTS WORKING!")
        print("\nKey improvements validated:")
        print("  ‚úÖ Adjacency matrix normalization with epsilon protection")
        print("  ‚úÖ Enhanced per-geo feature normalization")
        print("  ‚úÖ Proper Xavier/Glorot weight initialization")
        print("  ‚úÖ Robust NaN/Inf detection and early termination")
        print("  ‚úÖ Strict numerical error handling mode")
        print("  ‚úÖ Overall training stability in null scenarios")
        print("\nSTGCN numerical stability significantly improved!")
    else:
        print(f"\n‚ö†Ô∏è {failed} test(s) failed. Review the improvements.")
    
    return failed == 0


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)