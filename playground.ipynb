{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geo-Experiment Playground\n",
    "\n",
    "This notebook provides an interactive environment for experimenting with the geo-experiment evaluation framework.\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import our modules\n",
    "from data_simulation.generators import SimpleNullGenerator, DataConfig\n",
    "from assignment.methods import RandomAssignment, KMeansEmbeddingAssignment, PrognosticScoreAssignment, EmbeddingBasedAssignment, HybridEmbeddingAssignment\n",
    "from assignment.spatial_utils import add_spectral_spatial_embedding\n",
    "from assignment.stratified_utils import stratified_assignment_within_clusters, evaluate_cluster_balance, print_balance_summary\n",
    "from reporting.models import MeanMatchingModel, GBRModel, TBRModel, SyntheticControlModel\n",
    "from evaluation.metrics import EvaluationRunner, EvaluationConfig\n",
    "from diagnostics.plots import DiagnosticPlotter\n",
    "from pipeline.runner import ExperimentRunner\n",
    "from pipeline.config import ExperimentConfig\n",
    "\n",
    "# Set style\n",
    "plt.style.use('default')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"‚úÖ All modules imported successfully!\")\n",
    "print(\"üìä Available assignment methods:\")\n",
    "print(\"  ‚Ä¢ RandomAssignment: Simple random assignment\")\n",
    "print(\"  ‚Ä¢ KMeansEmbeddingAssignment: K-means clustering on features\")\n",
    "print(\"  ‚Ä¢ PrognosticScoreAssignment: OLS-based prognostic scoring\")\n",
    "print(\"  ‚Ä¢ EmbeddingBasedAssignment: General embedding approach (neural + spatial)\")\n",
    "print(\"  ‚Ä¢ HybridEmbeddingAssignment: Semi-supervised prediction-aware assignment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Start: Single Experiment\n",
    "\n",
    "Let's start with a simple single experiment to understand the framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple configuration\n",
    "config = ExperimentConfig(\n",
    "    n_geos=20,\n",
    "    n_days=60,\n",
    "    pre_period_days=40,\n",
    "    eval_period_days=20,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Run a single experiment\n",
    "runner = ExperimentRunner(config)\n",
    "results = runner.run_single_experiment(show_plots=True)\n",
    "\n",
    "print(f\"\\nüìä Single Experiment Results:\")\n",
    "print(f\"iROAS Estimate: {results['iroas_estimate']:.4f}\")\n",
    "print(f\"95% CI: [{results['iroas_ci'][0]:.4f}, {results['iroas_ci'][1]:.4f}]\")\n",
    "print(f\"CI Width: {results['ci_width']:.4f}\")\n",
    "print(f\"Significant: {results['significant']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Evaluation Example\n",
    "\n",
    "Now let's run a complete evaluation across multiple simulations to see how the method performs statistically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a full evaluation with the same configuration\n",
    "# Using smaller numbers for faster execution in the playground\n",
    "full_eval_config = ExperimentConfig(\n",
    "    n_geos=30,           # Moderate number of geos\n",
    "    n_days=60,           # 60 days total\n",
    "    pre_period_days=40,  # 40 days for training\n",
    "    eval_period_days=20, # 20 days for evaluation\n",
    "    n_simulations=50,    # 50 simulations (increase for more robust results)\n",
    "    n_bootstrap=200,     # 200 bootstrap samples per simulation\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(\"üîÑ Running full evaluation (this may take a minute)...\")\n",
    "print(f\"Configuration: {full_eval_config.n_simulations} simulations, {full_eval_config.n_geos} geos each\")\n",
    "\n",
    "# Create runner and run evaluation\n",
    "eval_runner = ExperimentRunner(full_eval_config)\n",
    "\n",
    "# Add all reporting models for comparison\n",
    "eval_runner.add_reporting_method('GBR', GBRModel())\n",
    "eval_runner.add_reporting_method('TBR', TBRModel())\n",
    "eval_runner.add_reporting_method('SCM', SyntheticControlModel())\n",
    "\n",
    "detailed_results, summary_results = eval_runner.run_full_evaluation(verbose=True)\n",
    "\n",
    "print(\"\\nüìà Summary Results:\")\n",
    "print(summary_results)\n",
    "\n",
    "# Create visualization\n",
    "print(\"\\nüìä Creating results visualization...\")\n",
    "fig = eval_runner.plot_results(detailed_results)\n",
    "plt.show()\n",
    "\n",
    "# Additional insights\n",
    "print(f\"\\nüîç Key Insights:\")\n",
    "print(f\"‚Ä¢ Average iROAS estimate: {detailed_results['iroas_estimate'].mean():.4f}\")\n",
    "print(f\"‚Ä¢ Standard deviation of estimates: {detailed_results['iroas_estimate'].std():.4f}\")\n",
    "print(f\"‚Ä¢ False positive rate: {summary_results['false_positive_rate'].iloc[0]:.3f} (should be ~0.05)\")\n",
    "print(f\"‚Ä¢ Coverage rate: {summary_results['coverage_rate'].iloc[0]:.3f} (should be ~0.95)\")\n",
    "print(f\"‚Ä¢ Mean CI width: {summary_results['mean_ci_width'].iloc[0]:.4f}\")\n",
    "\n",
    "# Show distribution of estimates\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(detailed_results['iroas_estimate'], bins=20, alpha=0.7, edgecolor='black')\n",
    "plt.axvline(0, color='red', linestyle='--', label='True iROAS (0)')\n",
    "plt.xlabel('iROAS Estimate')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of iROAS Estimates')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(detailed_results['ci_width'], bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "plt.xlabel('Confidence Interval Width')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of CI Widths')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation Experiments\n",
    "\n",
    "Let's experiment with different data generation parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data with different noise levels\n",
    "low_noise_config = DataConfig(\n",
    "    n_geos=30,\n",
    "    n_days=90,\n",
    "    daily_sales_noise=100,  # Low noise\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "high_noise_config = DataConfig(\n",
    "    n_geos=30,\n",
    "    n_days=90,\n",
    "    daily_sales_noise=1000,  # High noise\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "# Generate both datasets\n",
    "low_noise_gen = SimpleNullGenerator(low_noise_config)\n",
    "high_noise_gen = SimpleNullGenerator(high_noise_config)\n",
    "\n",
    "panel_low, features_low = low_noise_gen.generate()\n",
    "panel_high, features_high = high_noise_gen.generate()\n",
    "\n",
    "# Compare variability\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot time series for first geo\n",
    "geo_low = panel_low[panel_low['geo'] == 'geo_000']\n",
    "geo_high = panel_high[panel_high['geo'] == 'geo_000']\n",
    "\n",
    "axes[0].plot(geo_low['date'], geo_low['sales'], label='Low Noise', alpha=0.8)\n",
    "axes[0].plot(geo_high['date'], geo_high['sales'], label='High Noise', alpha=0.8)\n",
    "axes[0].set_title('Sales Time Series Comparison (geo_000)')\n",
    "axes[0].set_ylabel('Sales')\n",
    "axes[0].legend()\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Plot distributions\n",
    "axes[1].hist(panel_low['sales'], alpha=0.6, label='Low Noise', bins=30)\n",
    "axes[1].hist(panel_high['sales'], alpha=0.6, label='High Noise', bins=30)\n",
    "axes[1].set_title('Sales Distribution Comparison')\n",
    "axes[1].set_xlabel('Sales')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Low noise std: {panel_low['sales'].std():.2f}\")\n",
    "print(f\"High noise std: {panel_high['sales'].std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment Method Testing\n",
    "\n",
    "Test different assignment strategies and their balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Comprehensive Assignment Method Comparison\nprint(\"üìä COMPREHENSIVE ASSIGNMENT METHOD COMPARISON\")\nprint(\"=\"*80)\n\n# Generate test data with all necessary features\nnp.random.seed(42)\ntest_geo_features = pd.DataFrame({\n    'geo': [f'geo_{i:03d}' for i in range(40)],\n    'base_sales': np.random.normal(12000, 4000, 40),\n    'base_spend': np.random.normal(6000, 2000, 40),\n    'covariate': np.random.normal(0, 1.5, 40),\n    'xy1': np.random.uniform(0, 100, 40),  # Spatial coordinates\n    'xy2': np.random.uniform(0, 100, 40)\n})\n\n# Create panel data for time-series methods\ndates = pd.date_range('2024-01-01', periods=60)\ntest_panel_data = []\nfor _, geo_row in test_geo_features.iterrows():\n    base_sales = geo_row['base_sales']\n    trend = np.random.normal(0, 50)\n    for day_idx, date in enumerate(dates):\n        sales = (base_sales + trend * day_idx + np.random.normal(0, 500) + \n                300 * np.sin(day_idx * 2 * np.pi / 7))  # Weekly seasonality\n        test_panel_data.append({\n            'geo': geo_row['geo'],\n            'date': date,\n            'sales': max(sales, 1000),\n            'spend_dollars': np.random.normal(5000, 1000)\n        })\ntest_panel_df = pd.DataFrame(test_panel_data)\n\nprint(f\"Dataset: {len(test_geo_features)} geos with {len(test_panel_df)} panel observations\")\n\n# Define all available assignment methods\nassignment_methods = {\n    'Random': {\n        'method': RandomAssignment(),\n        'description': 'Simple random assignment (baseline)',\n        'requires_panel': False,\n        'requires_spatial': False\n    },\n    'K-Means': {\n        'method': KMeansEmbeddingAssignment(n_clusters=5),\n        'description': 'K-means clustering on standardized features',\n        'requires_panel': False,\n        'requires_spatial': False\n    },\n    'Prognostic Score': {\n        'method': PrognosticScoreAssignment(n_strata=5),\n        'description': 'OLS-based prognostic scoring with stratification',\n        'requires_panel': True,\n        'requires_spatial': False\n    },\n    'Embedding-Based': {\n        'method': EmbeddingBasedAssignment(n_clusters=5, neural_epochs=15),\n        'description': 'Neural + spectral spatial embeddings',\n        'requires_panel': False,\n        'requires_spatial': True\n    },\n    'Hybrid Embedding': {\n        'method': HybridEmbeddingAssignment(n_clusters=5, neural_epochs=15),\n        'description': 'Semi-supervised: reconstruction + prediction loss',\n        'requires_panel': True,\n        'requires_spatial': True\n    }\n}\n\n# Create comprehensive comparison visualization\nfig, axes = plt.subplots(3, len(assignment_methods), figsize=(25, 15))\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"üéØ ASSIGNMENT METHOD DETAILED COMPARISON\")\nprint(\"=\"*80)\n\nbalance_summary = {}\nfor i, (method_name, method_info) in enumerate(assignment_methods.items()):\n    print(f\"\\nüîπ {method_name.upper()}:\")\n    print(f\"   {method_info['description']}\")\n    print(\"-\" * 60)\n    \n    try:\n        # Create assignment based on method requirements\n        if method_info['requires_panel'] and method_info['requires_spatial']:\n            # Hybrid embedding needs both\n            assignment_df = method_info['method'].assign(\n                test_geo_features, panel_data=test_panel_df, seed=42\n            )\n        elif method_info['requires_panel']:\n            # Prognostic score needs panel data\n            assignment_df = method_info['method'].assign(\n                test_geo_features[['geo', 'base_sales', 'base_spend', 'covariate']], \n                panel_data=test_panel_df, seed=42\n            )\n        elif method_info['requires_spatial']:\n            # Embedding-based needs spatial coordinates\n            assignment_df = method_info['method'].assign(test_geo_features, seed=42)\n        else:\n            # Random and K-means work with basic features\n            assignment_df = method_info['method'].assign(\n                test_geo_features[['geo', 'base_sales', 'base_spend', 'covariate']], seed=42\n            )\n        \n        # Merge for analysis\n        if method_info['requires_spatial']:\n            analysis_features = test_geo_features\n        else:\n            analysis_features = test_geo_features[['geo', 'base_sales', 'base_spend', 'covariate']]\n        \n        merged = analysis_features.merge(assignment_df, on='geo')\n        \n        # Print assignment summary\n        treatment_count = (assignment_df['assignment'] == 'treatment').sum()\n        control_count = (assignment_df['assignment'] == 'control').sum()\n        \n        print(f\"   Assignment: {treatment_count} treatment, {control_count} control\")\n        \n        # Handle cluster information\n        if 'cluster' not in assignment_df.columns:\n            assignment_df = assignment_df.copy()\n            assignment_df['cluster'] = 0  # Single cluster for methods without clustering\n            print(f\"   Structure: No clustering (all geos treated as single group)\")\n        else:\n            n_clusters = len(assignment_df['cluster'].unique())\n            cluster_dist = assignment_df['cluster'].value_counts().sort_index()\n            print(f\"   Structure: {n_clusters} clusters/strata\")\n            print(f\"   Distribution: {dict(cluster_dist)}\")\n        \n        # Evaluate balance\n        feature_cols = ['base_sales', 'base_spend', 'covariate']\n        balance_df = evaluate_cluster_balance(analysis_features, assignment_df, feature_cols)\n        \n        # Calculate balance metrics\n        overall_balance = balance_df[balance_df['cluster'] == 'Overall']\n        avg_smd = overall_balance['standardized_diff'].mean()\n        max_smd = overall_balance['standardized_diff'].max()\n        \n        balance_summary[method_name] = {\n            'avg_smd': avg_smd,\n            'max_smd': max_smd,\n            'treatment_count': treatment_count,\n            'control_count': control_count,\n            'n_clusters': len(assignment_df['cluster'].unique())\n        }\n        \n        # Print balance summary\n        print(f\"   Balance: Avg SMD = {avg_smd:.3f}, Max SMD = {max_smd:.3f}\")\n        balance_quality = (\"Excellent\" if avg_smd < 0.05 else \n                          \"Good\" if avg_smd < 0.1 else \n                          \"Moderate\" if avg_smd < 0.2 else \"Poor\")\n        print(f\"   Quality: {balance_quality} ({'‚úÖ' if avg_smd < 0.1 else '‚ö†Ô∏è' if avg_smd < 0.2 else '‚ùå'})\")\n        \n        # Visualization 1: Sales balance\n        sns.boxplot(data=merged, x='assignment', y='base_sales', ax=axes[0, i])\n        axes[0, i].set_title(f'{method_name}\\nSales Balance')\n        axes[0, i].set_ylabel('Base Sales' if i == 0 else '')\n        \n        # Visualization 2: Covariate balance with cluster information\n        if 'cluster' in assignment_df.columns and len(assignment_df['cluster'].unique()) > 1:\n            # Show clusters with different colors\n            palette = sns.color_palette(\"Set2\", n_colors=len(merged['cluster'].unique()))\n            sns.scatterplot(data=merged, x='assignment', y='covariate', \n                           hue='cluster', palette=palette, ax=axes[1, i], s=60, alpha=0.8)\n            axes[1, i].set_title(f'{method_name}\\nCovariate by Cluster')\n            if i < len(assignment_methods) - 1:  # Remove legend except for last plot\n                axes[1, i].get_legend().remove()\n        else:\n            sns.boxplot(data=merged, x='assignment', y='covariate', ax=axes[1, i])\n            axes[1, i].set_title(f'{method_name}\\nCovariate Balance')\n        axes[1, i].set_ylabel('Covariate' if i == 0 else '')\n        \n        # Visualization 3: Balance quality heatmap\n        balance_pivot = overall_balance.set_index('feature')['standardized_diff']\n        balance_matrix = balance_pivot.values.reshape(-1, 1)\n        \n        im = axes[2, i].imshow(balance_matrix, cmap='RdYlGn_r', aspect='auto', vmin=0, vmax=0.3)\n        axes[2, i].set_title(f'{method_name}\\nBalance Quality')\n        axes[2, i].set_yticks(range(len(feature_cols)))\n        axes[2, i].set_yticklabels(['Sales', 'Spend', 'Covariate'] if i == 0 else ['', '', ''])\n        axes[2, i].set_xticks([0])\n        axes[2, i].set_xticklabels(['SMD'])\n        \n        # Add text annotations\n        for j, val in enumerate(balance_matrix.flatten()):\n            color = 'white' if val > 0.15 else 'black'\n            axes[2, i].text(0, j, f'{val:.2f}', ha='center', va='center', color=color, fontweight='bold')\n    \n    except Exception as e:\n        print(f\"   ‚ùå Error: {str(e)}\")\n        balance_summary[method_name] = {'avg_smd': np.nan, 'error': str(e)}\n        \n        # Fill plots with error message\n        for row in range(3):\n            axes[row, i].text(0.5, 0.5, f'Error:\\n{str(e)[:30]}...', \n                            transform=axes[row, i].transAxes, ha='center', va='center')\n            axes[row, i].set_title(f'{method_name}\\n(Failed)')\n\nplt.tight_layout()\nplt.show()\n\n# Summary comparison table\nprint(\"\\n\" + \"=\"*80)\nprint(\"üìã SUMMARY COMPARISON TABLE\")\nprint(\"=\"*80)\n\nsummary_df = pd.DataFrame(balance_summary).T\nsummary_df = summary_df.dropna(subset=['avg_smd'])  # Remove failed methods\n\nif len(summary_df) > 0:\n    summary_df = summary_df.sort_values('avg_smd')\n    print(f\"{'Method':<18} {'Avg SMD':<8} {'Max SMD':<8} {'T/C Split':<12} {'Clusters':<8} {'Quality':<12}\")\n    print(\"-\" * 75)\n    \n    for method, row in summary_df.iterrows():\n        quality = (\"Excellent\" if row['avg_smd'] < 0.05 else \n                  \"Good\" if row['avg_smd'] < 0.1 else \n                  \"Moderate\" if row['avg_smd'] < 0.2 else \"Poor\")\n        split = f\"{int(row['treatment_count'])}/{int(row['control_count'])}\"\n        \n        print(f\"{method:<18} {row['avg_smd']:<8.3f} {row['max_smd']:<8.3f} {split:<12} {int(row['n_clusters']):<8} {quality:<12}\")\n\n# Final recommendations\nprint(f\"\\nüéØ RECOMMENDATIONS:\")\nprint(\"=\"*50)\nprint(\"‚Ä¢ Random: Use as baseline for comparison\")\nprint(\"‚Ä¢ K-Means: Good general-purpose method for feature-based balance\")\nprint(\"‚Ä¢ Prognostic Score: Best when historical outcomes predict future performance\")\nprint(\"‚Ä¢ Embedding-Based: Ideal when spatial structure matters\")\nprint(\"‚Ä¢ Hybrid Embedding: Most sophisticated, use when prediction accuracy is key\")\nprint(\"\\nüí° SMD Interpretation:\")\nprint(\"‚Ä¢ < 0.05: Excellent balance\")\nprint(\"‚Ä¢ 0.05-0.1: Good balance\") \nprint(\"‚Ä¢ 0.1-0.2: Moderate balance (acceptable)\")\nprint(\"‚Ä¢ > 0.2: Poor balance (concerning)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Assignment Methods\n",
    "\n",
    "Now let's test the more sophisticated assignment methods that use feature engineering and clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed Balance Analysis: Understanding Stratified Assignment\n",
    "print(\"üî¨ DETAILED BALANCE ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Generate focused test data\n",
    "np.random.seed(123)\n",
    "test_features = pd.DataFrame({\n",
    "    'geo': [f'geo_{i:03d}' for i in range(24)],\n",
    "    'base_sales': np.random.normal(10000, 3000, 24),\n",
    "    'base_spend': np.random.normal(5000, 1500, 24), \n",
    "    'covariate': np.random.normal(0, 2, 24)\n",
    "})\n",
    "\n",
    "print(f\"Test data: {len(test_features)} geos\")\n",
    "print(f\"Feature ranges:\")\n",
    "print(f\"  ‚Ä¢ base_sales: {test_features['base_sales'].min():.0f} - {test_features['base_sales'].max():.0f}\")\n",
    "print(f\"  ‚Ä¢ base_spend: {test_features['base_spend'].min():.0f} - {test_features['base_spend'].max():.0f}\")\n",
    "print(f\"  ‚Ä¢ covariate: {test_features['covariate'].min():.2f} - {test_features['covariate'].max():.2f}\")\n",
    "\n",
    "# Test K-Means method to show stratified assignment concept\n",
    "print(f\"\\nüéØ K-MEANS STRATIFIED ASSIGNMENT DEMO:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "kmeans_method = KMeansEmbeddingAssignment(n_clusters=3)\n",
    "kmeans_assignment = kmeans_method.assign(test_features, treatment_ratio=0.5, seed=123)\n",
    "\n",
    "# Show cluster formation and assignment within clusters\n",
    "merged_detailed = test_features.merge(kmeans_assignment, on='geo')\n",
    "\n",
    "print(\"\\nCluster formation and assignment:\")\n",
    "for cluster_id in sorted(merged_detailed['cluster'].unique()):\n",
    "    cluster_data = merged_detailed[merged_detailed['cluster'] == cluster_id]\n",
    "    treatment_in_cluster = (cluster_data['assignment'] == 'treatment').sum()\n",
    "    control_in_cluster = (cluster_data['assignment'] == 'control').sum()\n",
    "    \n",
    "    avg_sales = cluster_data['base_sales'].mean()\n",
    "    avg_spend = cluster_data['base_spend'].mean()\n",
    "    avg_cov = cluster_data['covariate'].mean()\n",
    "    \n",
    "    print(f\"\\n  Cluster {cluster_id}: {len(cluster_data)} geos total\")\n",
    "    print(f\"    Assignment: {treatment_in_cluster} treatment, {control_in_cluster} control\")\n",
    "    print(f\"    Avg features: sales={avg_sales:.0f}, spend={avg_spend:.0f}, cov={avg_cov:.2f}\")\n",
    "\n",
    "# Comprehensive balance evaluation\n",
    "print(f\"\\nüìä BALANCE EVALUATION:\")\n",
    "print(\"-\" * 30)\n",
    "balance_results = evaluate_cluster_balance(\n",
    "    test_features, \n",
    "    kmeans_assignment, \n",
    "    ['base_sales', 'base_spend', 'covariate']\n",
    ")\n",
    "\n",
    "print_balance_summary(balance_results, threshold=0.1)\n",
    "\n",
    "# Visualization of clusters and assignments\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Cluster visualization in feature space\n",
    "scatter = axes[0, 0].scatter(merged_detailed['base_sales'], merged_detailed['base_spend'], \n",
    "                           c=merged_detailed['cluster'], cmap='Set1', s=80, alpha=0.7)\n",
    "axes[0, 0].set_xlabel('Base Sales')\n",
    "axes[0, 0].set_ylabel('Base Spend')\n",
    "axes[0, 0].set_title('K-Means Clusters in Feature Space')\n",
    "plt.colorbar(scatter, ax=axes[0, 0], label='Cluster')\n",
    "\n",
    "# 2. Assignment within clusters\n",
    "colors = ['red' if x == 'treatment' else 'blue' for x in merged_detailed['assignment']]\n",
    "axes[0, 1].scatter(merged_detailed['base_sales'], merged_detailed['base_spend'], \n",
    "                  c=colors, s=80, alpha=0.7)\n",
    "axes[0, 1].set_xlabel('Base Sales')\n",
    "axes[0, 1].set_ylabel('Base Spend')\n",
    "axes[0, 1].set_title('Treatment/Control Assignment')\n",
    "axes[0, 1].legend(['Control', 'Treatment'])\n",
    "\n",
    "# 3. Balance comparison by cluster\n",
    "cluster_balance = balance_results[balance_results['cluster'] != 'Overall']\n",
    "if len(cluster_balance) > 0:\n",
    "    sns.barplot(data=cluster_balance, x='cluster', y='standardized_diff', \n",
    "               hue='feature', ax=axes[1, 0])\n",
    "    axes[1, 0].set_title('Within-Cluster Balance (SMD)')\n",
    "    axes[1, 0].axhline(y=0.1, color='red', linestyle='--', alpha=0.7, label='Balance Threshold')\n",
    "    axes[1, 0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# 4. Overall vs within-cluster balance\n",
    "overall_balance = balance_results[balance_results['cluster'] == 'Overall']\n",
    "avg_within_cluster = cluster_balance.groupby('feature')['standardized_diff'].mean().reset_index()\n",
    "avg_within_cluster['balance_type'] = 'Within-Cluster Avg'\n",
    "overall_balance_plot = overall_balance[['feature', 'standardized_diff']].copy()\n",
    "overall_balance_plot['balance_type'] = 'Overall'\n",
    "\n",
    "balance_comparison = pd.concat([\n",
    "    overall_balance_plot[['feature', 'standardized_diff', 'balance_type']], \n",
    "    avg_within_cluster[['feature', 'standardized_diff', 'balance_type']]\n",
    "])\n",
    "\n",
    "sns.barplot(data=balance_comparison, x='feature', y='standardized_diff', \n",
    "           hue='balance_type', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Overall vs Within-Cluster Balance')\n",
    "axes[1, 1].axhline(y=0.1, color='red', linestyle='--', alpha=0.7)\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüí° KEY CONCEPTS:\")\n",
    "print(\"‚Ä¢ Stratified assignment separates clustering from treatment assignment\")\n",
    "print(\"‚Ä¢ Each cluster contributes proportionally to treatment and control groups\")\n",
    "print(\"‚Ä¢ This prevents imbalance from assigning entire clusters to one group\")\n",
    "print(\"‚Ä¢ Balance is evaluated both overall and within each cluster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment Method Deep Dive\n",
    "\n",
    "Individual analysis of each assignment method to understand their clustering/stratification strategies and balance characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Embedding-Based Assignment Demonstration\nprint(\"üéØ EMBEDDING-BASED ASSIGNMENT DEMO\")\nprint(\"=\"*60)\nprint(\"Combines neural embeddings (learned features) + spectral spatial embeddings\")\n\n# Import the EmbeddingBasedAssignment method\nfrom assignment.methods import EmbeddingBasedAssignment\n\n# Generate test data with spatial coordinates\nnp.random.seed(2024)\nembedding_features = pd.DataFrame({\n    'geo': [f'geo_{i:03d}' for i in range(30)],\n    'base_sales': np.random.normal(15000, 5000, 30),\n    'base_spend': np.random.normal(7500, 2500, 30),\n    'covariate': np.random.normal(0, 2, 30),\n    # Spatial coordinates (e.g., latitude/longitude scaled)\n    'xy1': np.random.uniform(0, 100, 30),\n    'xy2': np.random.uniform(0, 100, 30)\n})\n\nprint(f\"\\nDataset: {len(embedding_features)} geos with features + spatial coordinates\")\nprint(f\"Features: {[col for col in embedding_features.columns if col not in ['geo', 'xy1', 'xy2']]}\")\nprint(f\"Spatial coords: ['xy1', 'xy2']\")\n\n# Test different configurations of the embedding method\nembedding_configs = {\n    'Default': EmbeddingBasedAssignment(neural_epochs=20),\n    'High Neural Dim': EmbeddingBasedAssignment(\n        neural_embedding_dim=12, \n        spatial_embedding_dim=3,\n        neural_epochs=20\n    ),\n    'More Clusters': EmbeddingBasedAssignment(\n        n_clusters=6,\n        neural_epochs=20\n    ),\n    'Custom Features': EmbeddingBasedAssignment(\n        feature_cols=['base_sales', 'covariate'],  # Skip base_spend\n        neural_epochs=20\n    )\n}\n\n# Create comprehensive visualization\nfig, axes = plt.subplots(2, len(embedding_configs), figsize=(20, 10))\n\nprint(f\"\\nüîç Testing {len(embedding_configs)} embedding-based configurations:\")\nprint(\"-\" * 70)\n\nfor i, (config_name, method) in enumerate(embedding_configs.items()):\n    print(f\"\\n{config_name.upper()}:\")\n    print(f\"  Neural dim: {method.neural_embedding_dim}, Spatial dim: {method.spatial_embedding_dim}\")\n    print(f\"  Clusters: {method.n_clusters}, Features: {method.feature_cols or 'default'}\")\n    \n    # Create assignment\n    assignment_df = method.assign(embedding_features, seed=2024)\n    merged_embedding = embedding_features.merge(assignment_df, on='geo')\n    \n    # Print summary\n    treatment_count = (assignment_df['assignment'] == 'treatment').sum()\n    control_count = (assignment_df['assignment'] == 'control').sum()\n    n_clusters_actual = len(assignment_df['cluster'].unique())\n    \n    print(f\"  Result: {treatment_count}T/{control_count}C across {n_clusters_actual} clusters\")\n    \n    # Evaluate balance\n    balance_results = evaluate_cluster_balance(\n        embedding_features, assignment_df, ['base_sales', 'base_spend', 'covariate']\n    )\n    \n    # Calculate average balance quality\n    overall_balance = balance_results[balance_results['cluster'] == 'Overall']\n    avg_smd = overall_balance['standardized_diff'].mean()\n    print(f\"  Avg SMD: {avg_smd:.3f} ({'Good' if avg_smd < 0.1 else 'Moderate' if avg_smd < 0.2 else 'Poor'} balance)\")\n    \n    # Top plot: Spatial distribution with clusters\n    scatter = axes[0, i].scatter(\n        merged_embedding['xy1'], merged_embedding['xy2'],\n        c=merged_embedding['cluster'], cmap='tab10', s=80, alpha=0.8\n    )\n    axes[0, i].set_xlabel('Spatial X1')\n    axes[0, i].set_ylabel('Spatial X2')\n    axes[0, i].set_title(f'{config_name}\\nSpatial Clusters')\n    \n    # Bottom plot: Feature space with treatment assignment\n    treatment_mask = merged_embedding['assignment'] == 'treatment'\n    axes[1, i].scatter(\n        merged_embedding.loc[treatment_mask, 'base_sales'],\n        merged_embedding.loc[treatment_mask, 'covariate'],\n        c='red', label='Treatment', s=80, alpha=0.8\n    )\n    axes[1, i].scatter(\n        merged_embedding.loc[~treatment_mask, 'base_sales'],\n        merged_embedding.loc[~treatment_mask, 'covariate'],\n        c='blue', label='Control', s=80, alpha=0.8\n    )\n    axes[1, i].set_xlabel('Base Sales')\n    axes[1, i].set_ylabel('Covariate')\n    axes[1, i].set_title(f'{config_name}\\nTreatment Assignment')\n    if i == 0:\n        axes[1, i].legend()\n\nplt.tight_layout()\nplt.show()\n\nprint(f\"\\nüéØ EMBEDDING-BASED KEY FEATURES:\")\nprint(\"=\"*50)\nprint(\"‚Ä¢ Neural embeddings: Learn representations from static geo features\")\nprint(\"‚Ä¢ Spatial embeddings: Capture geographic proximity via spectral methods\")\nprint(\"‚Ä¢ Combined embeddings: Merge learned + spatial representations\")\nprint(\"‚Ä¢ Stratified assignment: Balanced treatment/control within each cluster\")\nprint(\"‚Ä¢ General purpose: Works with limited data, fast training\")\n\n# Quick performance comparison with simpler methods\nprint(f\"\\n‚ö° QUICK PERFORMANCE COMPARISON:\")\nprint(\"-\" * 40)\n\ncomparison_methods = {\n    'Random': RandomAssignment(),\n    'K-Means': KMeansEmbeddingAssignment(n_clusters=4),\n    'Embedding-Based': EmbeddingBasedAssignment(n_clusters=4, neural_epochs=15)\n}\n\nbalance_scores = {}\nfor method_name, method in comparison_methods.items():\n    if method_name == 'Embedding-Based':\n        assignment = method.assign(embedding_features, seed=2024)\n    elif method_name == 'Random':\n        assignment = method.assign(embedding_features[['geo', 'base_sales', 'base_spend', 'covariate']], seed=2024)\n    else:  # K-Means\n        assignment = method.assign(embedding_features[['geo', 'base_sales', 'base_spend', 'covariate']], seed=2024)\n    \n    # Handle methods that don't create cluster column (like RandomAssignment)\n    if 'cluster' not in assignment.columns:\n        # Add dummy cluster for random assignment\n        assignment = assignment.copy()\n        assignment['cluster'] = 0  # All in one cluster for random assignment\n    \n    balance = evaluate_cluster_balance(\n        embedding_features[['geo', 'base_sales', 'base_spend', 'covariate']], \n        assignment, \n        ['base_sales', 'base_spend', 'covariate']\n    )\n    overall_smd = balance[balance['cluster'] == 'Overall']['standardized_diff'].mean()\n    balance_scores[method_name] = overall_smd\n    \n    treatment_count = (assignment['assignment'] == 'treatment').sum()\n    print(f\"{method_name:15}: {treatment_count}T/{30-treatment_count}C, Avg SMD = {overall_smd:.3f}\")\n\n# Visualize balance comparison\nplt.figure(figsize=(10, 6))\nmethods = list(balance_scores.keys())\nscores = list(balance_scores.values())\ncolors = ['skyblue', 'lightcoral', 'lightgreen']\n\nbars = plt.bar(methods, scores, color=colors, alpha=0.8, edgecolor='black')\nplt.axhline(y=0.1, color='red', linestyle='--', alpha=0.7, label='Good Balance Threshold')\nplt.ylabel('Average Standardized Mean Difference (SMD)')\nplt.title('Balance Quality Comparison: Embedding-Based vs Other Methods')\nplt.legend()\n\n# Add value labels on bars\nfor bar, score in zip(bars, scores):\n    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n             f'{score:.3f}', ha='center', va='bottom', fontweight='bold')\n\nplt.tight_layout()\nplt.show()\n\nprint(f\"\\nüí° INTERPRETATION:\")\nprint(\"‚Ä¢ Lower SMD = better balance between treatment and control groups\")\nprint(\"‚Ä¢ Embedding-based method combines feature learning + spatial awareness\")\nprint(\"‚Ä¢ Good for cases with static features and spatial structure\")\nprint(\"‚Ä¢ Neural component learns complex feature relationships\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Embedding Assignment (Semi-Supervised)\n",
    "\n",
    "Test the advanced HybridEmbeddingAssignment method that uses a hybrid loss function combining reconstruction (unsupervised) and prediction (supervised) objectives. This method is prediction-aware and requires panel data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid Embedding Assignment (Semi-Supervised) Demonstration\n",
    "print(\"üß† HYBRID EMBEDDING ASSIGNMENT DEMO\")\n",
    "print(\"=\"*60)\n",
    "print(\"Semi-supervised approach: Reconstruction (unsupervised) + Prediction (supervised)\")\n",
    "\n",
    "# Import the new HybridEmbeddingAssignment method\n",
    "from assignment.methods import HybridEmbeddingAssignment\n",
    "\n",
    "# Generate test data with time series (required for hybrid approach)\n",
    "np.random.seed(2025)\n",
    "n_geos = 20\n",
    "n_days = 50\n",
    "\n",
    "# Create geo features with spatial coordinates\n",
    "hybrid_geo_features = pd.DataFrame({\n",
    "    'geo': [f'geo_{i:03d}' for i in range(n_geos)],\n",
    "    'xy1': np.random.uniform(0, 100, n_geos),\n",
    "    'xy2': np.random.uniform(0, 100, n_geos)\n",
    "})\n",
    "\n",
    "# Create panel data with time series patterns\n",
    "dates = pd.date_range('2024-01-01', periods=n_days)\n",
    "panel_data = []\n",
    "\n",
    "for _, geo_row in hybrid_geo_features.iterrows():\n",
    "    # Each geo has a different base sales level and trend\n",
    "    base_sales = np.random.normal(12000, 3000)\n",
    "    trend = np.random.normal(0, 50)  # Some geos grow, others decline\n",
    "    \n",
    "    for day_idx, date in enumerate(dates):\n",
    "        sales = (base_sales + \n",
    "                trend * day_idx + \n",
    "                np.random.normal(0, 800) +  # Daily noise\n",
    "                500 * np.sin(day_idx * 2 * np.pi / 7))  # Weekly seasonality\n",
    "        \n",
    "        panel_data.append({\n",
    "            'geo': geo_row['geo'],\n",
    "            'date': date,\n",
    "            'sales': max(sales, 1000),  # Ensure positive sales\n",
    "            'spend_dollars': np.random.normal(5000, 1000)\n",
    "        })\n",
    "\n",
    "hybrid_panel_data = pd.DataFrame(panel_data)\n",
    "\n",
    "print(f\"\\nDataset: {n_geos} geos with {n_days} days of time series data\")\n",
    "print(f\"Panel data shape: {hybrid_panel_data.shape}\")\n",
    "print(f\"Spatial coords: ['xy1', 'xy2']\")\n",
    "print(f\"Time series: Sales data with trends and seasonality\")\n",
    "\n",
    "# Test different hybrid configurations\n",
    "print(f\"\\nüî¨ HYBRID LOSS CONFIGURATIONS:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "hybrid_configs = {\n",
    "    'Balanced': HybridEmbeddingAssignment(\n",
    "        reconstruction_weight=0.5,\n",
    "        prediction_weight=0.25,\n",
    "        regularization_weight=0.25,\n",
    "        neural_epochs=20,\n",
    "        n_clusters=3\n",
    "    ),\n",
    "    'Prediction-Focused': HybridEmbeddingAssignment(\n",
    "        reconstruction_weight=0.3,\n",
    "        prediction_weight=0.5,    # Higher emphasis on prediction\n",
    "        regularization_weight=0.2,\n",
    "        neural_epochs=20,\n",
    "        n_clusters=3\n",
    "    ),\n",
    "    'Reconstruction-Focused': HybridEmbeddingAssignment(\n",
    "        reconstruction_weight=0.6,   # Higher emphasis on reconstruction\n",
    "        prediction_weight=0.2,\n",
    "        regularization_weight=0.2,\n",
    "        neural_epochs=20,\n",
    "        n_clusters=3\n",
    "    )\n",
    "}\n",
    "\n",
    "# Run experiments with different loss configurations\n",
    "results_comparison = {}\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "for i, (config_name, method) in enumerate(hybrid_configs.items()):\n",
    "    print(f\"\\n{config_name.upper()}:\")\n",
    "    print(f\"  Loss weights - Recon: {method.reconstruction_weight:.1f}, \" +\n",
    "          f\"Pred: {method.prediction_weight:.1f}, Reg: {method.regularization_weight:.1f}\")\n",
    "    \n",
    "    # Create assignment\n",
    "    assignment_df = method.assign(\n",
    "        hybrid_geo_features, \n",
    "        panel_data=hybrid_panel_data, \n",
    "        seed=2025\n",
    "    )\n",
    "    \n",
    "    # Merge for analysis\n",
    "    merged_hybrid = hybrid_geo_features.merge(assignment_df, on='geo')\n",
    "    \n",
    "    # Print summary\n",
    "    treatment_count = (assignment_df['assignment'] == 'treatment').sum()\n",
    "    control_count = (assignment_df['assignment'] == 'control').sum()\n",
    "    n_clusters_actual = len(assignment_df['cluster'].unique())\n",
    "    \n",
    "    print(f\"  Result: {treatment_count}T/{control_count}C across {n_clusters_actual} clusters\")\n",
    "    \n",
    "    # Store results for comparison\n",
    "    results_comparison[config_name] = {\n",
    "        'assignment_df': assignment_df,\n",
    "        'merged_data': merged_hybrid,\n",
    "        'treatment_count': treatment_count,\n",
    "        'control_count': control_count\n",
    "    }\n",
    "    \n",
    "    # Visualize spatial clustering\n",
    "    scatter = axes[0, i].scatter(\n",
    "        merged_hybrid['xy1'], merged_hybrid['xy2'],\n",
    "        c=merged_hybrid['cluster'], cmap='Set1', s=100, alpha=0.8, edgecolor='black'\n",
    "    )\n",
    "    axes[0, i].set_xlabel('Spatial X1')\n",
    "    axes[0, i].set_ylabel('Spatial X2')\n",
    "    axes[0, i].set_title(f'{config_name}\\nSpatial Clusters')\n",
    "    \n",
    "    # Visualize treatment assignment\n",
    "    treatment_mask = merged_hybrid['assignment'] == 'treatment'\n",
    "    axes[1, i].scatter(\n",
    "        merged_hybrid.loc[treatment_mask, 'xy1'],\n",
    "        merged_hybrid.loc[treatment_mask, 'xy2'],\n",
    "        c='red', label='Treatment', s=100, alpha=0.8, edgecolor='black'\n",
    "    )\n",
    "    axes[1, i].scatter(\n",
    "        merged_hybrid.loc[~treatment_mask, 'xy1'],\n",
    "        merged_hybrid.loc[~treatment_mask, 'xy2'],\n",
    "        c='blue', label='Control', s=100, alpha=0.8, edgecolor='black'\n",
    "    )\n",
    "    axes[1, i].set_xlabel('Spatial X1')\n",
    "    axes[1, i].set_ylabel('Spatial X2')\n",
    "    axes[1, i].set_title(f'{config_name}\\nTreatment Assignment')\n",
    "    if i == 0:\n",
    "        axes[1, i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compare the different approaches\n",
    "print(f\"\\nüìä PERFORMANCE ANALYSIS:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"Analyzing how different loss weightings affect cluster formation...\")\n",
    "\n",
    "# Analyze sales patterns by cluster for each method\n",
    "for config_name, results in results_comparison.items():\n",
    "    print(f\"\\n{config_name.upper()} ANALYSIS:\")\n",
    "    \n",
    "    # Get sales data for this assignment\n",
    "    assignment_with_sales = results['assignment_df'].merge(\n",
    "        hybrid_panel_data.groupby('geo')['sales'].mean().reset_index(), \n",
    "        on='geo'\n",
    "    )\n",
    "    \n",
    "    # Analyze clusters\n",
    "    cluster_stats = assignment_with_sales.groupby('cluster').agg({\n",
    "        'sales': ['mean', 'std', 'count'],\n",
    "        'assignment': lambda x: f\"{(x=='treatment').sum()}T/{(x=='control').sum()}C\"\n",
    "    }).round(0)\n",
    "    \n",
    "    cluster_stats.columns = ['Avg_Sales', 'Sales_Std', 'Count', 'T/C_Split']\n",
    "    print(cluster_stats.to_string())\n",
    "\n",
    "print(f\"\\nüéØ HYBRID EMBEDDING KEY ADVANTAGES:\")\n",
    "print(\"=\"*50)\n",
    "print(\"‚Ä¢ Semi-supervised learning: Combines unsupervised (reconstruction) + supervised (prediction)\")\n",
    "print(\"‚Ä¢ Prediction-aware: Neural embeddings learn to predict future sales outcomes\")\n",
    "print(\"‚Ä¢ Time series intelligence: Uses historical patterns, not just static features\")\n",
    "print(\"‚Ä¢ Tunable objectives: Adjust loss weights based on prediction vs balance priorities\")\n",
    "print(\"‚Ä¢ Spatial regularization: Geographic structure preserved through spectral embeddings\")\n",
    "\n",
    "# Demonstrate the prediction capability\n",
    "print(f\"\\nüîÆ PREDICTION AWARENESS DEMO:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Use the balanced configuration for this demo\n",
    "method = hybrid_configs['Balanced']\n",
    "\n",
    "# Show how the method splits time series data\n",
    "print(\"Time series data splitting:\")\n",
    "pre_period_data, prediction_targets, common_geos = method._prepare_time_series_data(hybrid_panel_data)\n",
    "\n",
    "print(f\"‚Ä¢ Pre-period data shape: {pre_period_data.shape} (geos √ó time_steps)\")\n",
    "print(f\"‚Ä¢ Prediction targets shape: {prediction_targets.shape} (future sales per geo)\")\n",
    "print(f\"‚Ä¢ Pre-period uses: {pre_period_data.shape[1]} days ({method.pre_period_fraction:.1%} of timeline)\")\n",
    "print(f\"‚Ä¢ Prediction period: {int(n_days * method.prediction_fraction)} days ({method.prediction_fraction:.1%} of timeline)\")\n",
    "\n",
    "# Show sales distribution\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(pre_period_data.mean(axis=1), bins=15, alpha=0.7, edgecolor='black')\n",
    "plt.xlabel('Average Pre-Period Sales')\n",
    "plt.ylabel('Number of Geos')\n",
    "plt.title('Pre-Period Sales Distribution\\n(Used for Learning Embeddings)')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(prediction_targets, bins=15, alpha=0.7, color='orange', edgecolor='black')\n",
    "plt.xlabel('Future Sales Target')\n",
    "plt.ylabel('Number of Geos')\n",
    "plt.title('Prediction Targets\\n(Used for Supervised Learning)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüí° WHEN TO USE HYBRID EMBEDDING:\")\n",
    "print(\"‚Ä¢ Rich panel data available (time series for each geo)\")\n",
    "print(\"‚Ä¢ Want assignments that consider likely future outcomes\")\n",
    "print(\"‚Ä¢ Care about both balance AND prediction accuracy\")\n",
    "print(\"‚Ä¢ Have computational resources for neural network training\")\n",
    "print(\"‚Ä¢ Geographic spillovers are important (spatial component)\")\n",
    "\n",
    "print(f\"\\nüîÑ COMPARISON WITH OTHER METHODS:\")\n",
    "print(\"‚Ä¢ EmbeddingBasedAssignment: Static features, faster, less data required\")\n",
    "print(\"‚Ä¢ HybridEmbeddingAssignment: Time series, prediction-aware, more sophisticated\")\n",
    "print(\"‚Ä¢ Both use spatial embeddings and stratified assignment for balance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance Comparison\n",
    "\n",
    "Run a small evaluation to see how methods perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstration of CSV and Plot Output Functionality\n",
    "print(\"üíæ CSV AND PLOT OUTPUT DEMO\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create a configuration for output demonstration\n",
    "output_config = ExperimentConfig(\n",
    "    n_geos=20,\n",
    "    n_days=50,\n",
    "    pre_period_days=35,\n",
    "    eval_period_days=15,\n",
    "    n_simulations=10,  # Small number for demo\n",
    "    n_bootstrap=100,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Create runner with multiple assignment methods for comparison\n",
    "output_runner = ExperimentRunner(output_config)\n",
    "output_runner.add_assignment_method('K-Means', KMeansEmbeddingAssignment(n_clusters=4))\n",
    "output_runner.add_assignment_method('Prognostic', PrognosticScoreAssignment(n_strata=4))\n",
    "\n",
    "print(f\"Configuration: {output_config.n_simulations} simulations, {output_config.n_geos} geos\")\n",
    "print(f\"Assignment methods: {list(output_runner.assignment_methods.keys())}\")\n",
    "\n",
    "# Run evaluation with output files\n",
    "print(f\"\\nüìä Running evaluation with CSV and plot output...\")\n",
    "detailed_results, summary_results = output_runner.run_full_evaluation(\n",
    "    verbose=True,\n",
    "    save_csv=True,           # Save results as CSV files\n",
    "    save_plots=True,         # Save plots as PNG files  \n",
    "    output_dir=\"demo_results\" # Output directory\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Files saved to 'demo_results' directory!\")\n",
    "print(f\"üìÑ Generated files:\")\n",
    "print(f\"  ‚Ä¢ evaluation_summary_[timestamp].csv - Key performance metrics\")\n",
    "print(f\"  ‚Ä¢ detailed_results_[timestamp].csv - All simulation results\")  \n",
    "print(f\"  ‚Ä¢ evaluation_results_[timestamp].png - Main results visualization\")\n",
    "print(f\"  ‚Ä¢ summary_metrics_[timestamp].png - Performance metrics charts\")\n",
    "print(f\"  ‚Ä¢ method_comparison_[timestamp].png - Method comparison heatmap\")\n",
    "\n",
    "# Also demonstrate single experiment output\n",
    "print(f\"\\nüî¨ Running single experiment with plot saving...\")\n",
    "single_results = output_runner.run_single_experiment(\n",
    "    show_plots=False,        # Don't display plots\n",
    "    save_plots=True,         # Save plots to files\n",
    "    output_dir=\"demo_results/single_experiment\"\n",
    ")\n",
    "\n",
    "print(f\"\\nüí° Use Cases:\")\n",
    "print(f\"‚Ä¢ save_csv=True: Generate reports, share results, further analysis\")\n",
    "print(f\"‚Ä¢ save_plots=True: Include in presentations, documentation, papers\")\n",
    "print(f\"‚Ä¢ Timestamps prevent file overwrites\")\n",
    "print(f\"‚Ä¢ Organized output directories keep results structured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick evaluation with small number of simulations\n",
    "quick_config = ExperimentConfig(\n",
    "    n_geos=25,\n",
    "    n_days=50,\n",
    "    pre_period_days=35,\n",
    "    eval_period_days=15,\n",
    "    n_simulations=20,  # Small for quick testing\n",
    "    n_bootstrap=100,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "runner = ExperimentRunner(quick_config)\n",
    "detailed_results, summary_results = runner.run_full_evaluation(verbose=True)\n",
    "\n",
    "# Plot results\n",
    "fig = runner.plot_results(detailed_results)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Experiments\n",
    "\n",
    "This section is for your own experiments and testing new ideas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß™ Experiment with different parameter combinations\n",
    "\n",
    "# Example: How does the number of geos affect CI width?\n",
    "geo_counts = [10, 25, 50, 100]\n",
    "ci_widths = []\n",
    "\n",
    "for n_geos in geo_counts:\n",
    "    config = ExperimentConfig(\n",
    "        n_geos=n_geos,\n",
    "        n_days=60,\n",
    "        pre_period_days=40,\n",
    "        eval_period_days=20,\n",
    "        n_simulations=10,  # Small for speed\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    runner = ExperimentRunner(config)\n",
    "    detailed_results, _ = runner.run_full_evaluation(verbose=False)\n",
    "    \n",
    "    avg_ci_width = detailed_results['ci_width'].mean()\n",
    "    ci_widths.append(avg_ci_width)\n",
    "    \n",
    "    print(f\"n_geos={n_geos}: avg CI width = {avg_ci_width:.3f}\")\n",
    "\n",
    "# Plot relationship\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(geo_counts, ci_widths, 'o-', linewidth=2, markersize=8)\n",
    "plt.xlabel('Number of Geos')\n",
    "plt.ylabel('Average CI Width')\n",
    "plt.title('CI Width vs Number of Geos')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ Your experiments here!\n",
    "\n",
    "# Ideas to try:\n",
    "# 1. Effect of noise level on false positive rates\n",
    "# 2. Optimal pre-period vs evaluation period lengths\n",
    "# 3. Impact of treatment ratio on power\n",
    "# 4. Bootstrap sample size vs CI stability\n",
    "\n",
    "# Example template:\n",
    "# config = ExperimentConfig(\n",
    "#     n_geos=...,\n",
    "#     n_days=...,\n",
    "#     # ... other parameters\n",
    "# )\n",
    "# runner = ExperimentRunner(config)\n",
    "# results = runner.run_single_experiment(show_plots=True)\n",
    "\n",
    "print(\"üöÄ Ready for your experiments!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Development Notes\n",
    "\n",
    "Use this section for notes, debugging, and development work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Development and debugging space\n",
    "\n",
    "# Quick data validation\n",
    "config = DataConfig(n_geos=5, n_days=10, seed=999)\n",
    "gen = SimpleNullGenerator(config)\n",
    "panel, features = gen.generate()\n",
    "\n",
    "print(\"Panel data sample:\")\n",
    "print(panel.head())\n",
    "print(f\"\\nPanel shape: {panel.shape}\")\n",
    "print(f\"Features shape: {features.shape}\")\n",
    "print(f\"Validation: {gen.validate_data(panel, features)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}